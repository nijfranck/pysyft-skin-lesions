{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MNIST', 'image_processing_templates.ipynb', '.ipynb_checkpoints', 'table.csv', 'images', '.DS_Store']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Python libraries\n",
    "\n",
    "import os, cv2, itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Pytorch libraries\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# to make the results are reproducible\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "print(os.listdir('../data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18997\n"
     ]
    }
   ],
   "source": [
    "directory = '../data/images/'\n",
    "\n",
    "image_path = glob(os.path.join(directory, '*.jpg'))\n",
    "imageid = {os.path.splitext(os.path.basename(x))[0]: x for x in image_path}\n",
    "print(len(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_type = {\n",
    "    'MEL': 'Melanoma',\n",
    "    'NV': 'Naevus',\n",
    "    'BCC': 'Basal Cell Carcinoma',\n",
    "    'AK': 'IEC/Bowens disease',\n",
    "    'BKL': 'Seborrhoeic keratosis',\n",
    "    'DF': 'dermatofibroima',\n",
    "    'VASC': 'vascular lesions',\n",
    "    'SCC': 'Squamous cell carcinom',\n",
    "    'UNK': 'Keratosis pilaris'\n",
    "}\n",
    "\n",
    "lesion_category = {\n",
    "    'MEL': 0,\n",
    "    'NV':  1,\n",
    "    'BCC': 2,\n",
    "    'AK':  3,\n",
    "    'BKL': 4,\n",
    "    'DF':  5,\n",
    "    'VASC': 6,\n",
    "    'SCC': 7,\n",
    "    'UNK': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_img_mean_std(image_paths):\n",
    "    \"\"\"\n",
    "        computing the mean and std of three channel on the whole dataset,\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "\n",
    "    img_h, img_w = 224, 224\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    means.reverse()  # BGR --> RGB\n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    return means,stdevs\n",
    "\n",
    "#norm_mean, norm_std = compute_img_mean_std(image_path)\n",
    "# shape (224, 224, 3, 18997)\n",
    "norm_mean = [0.7851518, 0.6649233, 0.6525781]\n",
    "norm_std = [0.17073259, 0.21847703, 0.2293689]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18997, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>image</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>DiagnosisDescriptions</th>\n",
       "      <th>DiagnosisSCARD</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>...</th>\n",
       "      <th>VASC</th>\n",
       "      <th>SCC</th>\n",
       "      <th>UNK</th>\n",
       "      <th>Count_classes</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>hash</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Unnamed: 0.1, Unnamed: 0.1.1, image, ImageName, lesion_id, DiagnosisDescriptions, DiagnosisSCARD, MEL, NV, BCC, AK, BKL, DF, VASC, SCC, UNK, Count_classes, w, h, hash, path, cell_type, cell_type_idx]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('table.csv')\n",
    "lesion_code_list = lesion_type.keys()\n",
    "df['path'] = df['image'].map(imageid.get)\n",
    "df['cell_type'] = df[lesion_code_list].idxmax(axis=1).map(lesion_type.get)\n",
    "df['cell_type_idx'] = df[lesion_code_list].idxmax(axis=1).map(lesion_category.get)\n",
    "print(df.shape)\n",
    "bool_series = pd.isnull(df[\"image\"])  \n",
    "df[bool_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15197, 24) (1900, 24) (1900, 24)\n"
     ]
    }
   ],
   "source": [
    "# train, val split\n",
    "y = df['cell_type_idx']\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state = 101, stratify=y)\n",
    "df_val, df_test = train_test_split(df_val, test_size = 0.5, random_state = 101, stratify=df_val['cell_type_idx'])\n",
    "print(df_train.shape, df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    486\n",
       "2    398\n",
       "3    320\n",
       "8    260\n",
       "4    232\n",
       "7     89\n",
       "0     73\n",
       "5     28\n",
       "6     14\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Naevus                    486\n",
       "Basal Cell Carcinoma      398\n",
       "IEC/Bowens disease        320\n",
       "Keratosis pilaris         260\n",
       "Seborrhoeic keratosis     232\n",
       "Squamous cell carcinom     89\n",
       "Melanoma                   73\n",
       "dermatofibroima            28\n",
       "vascular lesions           14\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>image</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>DiagnosisDescriptions</th>\n",
       "      <th>DiagnosisSCARD</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>...</th>\n",
       "      <th>SCC</th>\n",
       "      <th>UNK</th>\n",
       "      <th>Count_classes</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>hash</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "      <th>train_or_val_or_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC_1000000</td>\n",
       "      <td>002sMOUIQD5w7qL120190411010815030247.jpeg</td>\n",
       "      <td>2024373</td>\n",
       "      <td>LEFT TIP OF SHOULDER: CONSISTENT WITH MELANOMA...</td>\n",
       "      <td>Melanoma - in situ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2317</td>\n",
       "      <td>2317</td>\n",
       "      <td>0c6097583cfad9cce5c4cf094be826f7</td>\n",
       "      <td>../data/images/ISIC_1000000.jpg</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_1000001</td>\n",
       "      <td>00rK0idbwy0PxNi420181219033635545026.jpeg</td>\n",
       "      <td>1668238</td>\n",
       "      <td>STERNUM: LICHENOID ACTINIC KERATOSIS</td>\n",
       "      <td>Solar keratosis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2877</td>\n",
       "      <td>2877</td>\n",
       "      <td>fb7099d23536972d11f825cd7e038c67</td>\n",
       "      <td>../data/images/ISIC_1000001.jpg</td>\n",
       "      <td>IEC/Bowens disease</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_1000002</td>\n",
       "      <td>01udcynfZrZmuOiQ20190304222024216112.jpeg</td>\n",
       "      <td>1914403</td>\n",
       "      <td>LEFT FOREHEAD:  -MODERATELY ATYPICAL JUNCTIONA...</td>\n",
       "      <td>Naevus - dysplastic/Clark</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1783</td>\n",
       "      <td>1783</td>\n",
       "      <td>541e383dd5e78d1da34dae882cbee940</td>\n",
       "      <td>../data/images/ISIC_1000002.jpg</td>\n",
       "      <td>Naevus</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_1000003</td>\n",
       "      <td>027ryniVjJC4Jn1r20190219000735706379.jpeg</td>\n",
       "      <td>1874618</td>\n",
       "      <td>LEFT ANTERIOR CHEST:  PIGMENTED SEBORRHOEIC KE...</td>\n",
       "      <td>Seborrhoeic keratosis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2295</td>\n",
       "      <td>2295</td>\n",
       "      <td>ff00ee82c9d240453d6f5da4522cfb6e</td>\n",
       "      <td>../data/images/ISIC_1000003.jpg</td>\n",
       "      <td>Seborrhoeic keratosis</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>ISIC_1000004</td>\n",
       "      <td>02ntxrsyUG4OxVoi20190822033432889200.jpeg</td>\n",
       "      <td>2550168</td>\n",
       "      <td>LEFT PARIETAL SCALP: ACTINIC KERATOSIS WITH AT...</td>\n",
       "      <td>IEC/Bowens disease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2317</td>\n",
       "      <td>2317</td>\n",
       "      <td>e89d64eadaf1a1af2e273c001edadda2</td>\n",
       "      <td>../data/images/ISIC_1000004.jpg</td>\n",
       "      <td>IEC/Bowens disease</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1         image  \\\n",
       "0           0             0               0  ISIC_1000000   \n",
       "1           1             1               1  ISIC_1000001   \n",
       "2           2             2               2  ISIC_1000002   \n",
       "3           3             3               3  ISIC_1000003   \n",
       "4           4             4               4  ISIC_1000004   \n",
       "\n",
       "                                   ImageName  lesion_id  \\\n",
       "0  002sMOUIQD5w7qL120190411010815030247.jpeg    2024373   \n",
       "1  00rK0idbwy0PxNi420181219033635545026.jpeg    1668238   \n",
       "2  01udcynfZrZmuOiQ20190304222024216112.jpeg    1914403   \n",
       "3  027ryniVjJC4Jn1r20190219000735706379.jpeg    1874618   \n",
       "4  02ntxrsyUG4OxVoi20190822033432889200.jpeg    2550168   \n",
       "\n",
       "                               DiagnosisDescriptions  \\\n",
       "0  LEFT TIP OF SHOULDER: CONSISTENT WITH MELANOMA...   \n",
       "1               STERNUM: LICHENOID ACTINIC KERATOSIS   \n",
       "2  LEFT FOREHEAD:  -MODERATELY ATYPICAL JUNCTIONA...   \n",
       "3  LEFT ANTERIOR CHEST:  PIGMENTED SEBORRHOEIC KE...   \n",
       "4  LEFT PARIETAL SCALP: ACTINIC KERATOSIS WITH AT...   \n",
       "\n",
       "              DiagnosisSCARD  MEL  NV  ...  SCC  UNK  Count_classes     w  \\\n",
       "0         Melanoma - in situ    1   0  ...    0    0              1  2317   \n",
       "1            Solar keratosis    0   0  ...    0    0              1  2877   \n",
       "2  Naevus - dysplastic/Clark    0   1  ...    0    0              1  1783   \n",
       "3      Seborrhoeic keratosis    0   0  ...    0    0              1  2295   \n",
       "4         IEC/Bowens disease    0   0  ...    0    0              1  2317   \n",
       "\n",
       "      h                              hash                             path  \\\n",
       "0  2317  0c6097583cfad9cce5c4cf094be826f7  ../data/images/ISIC_1000000.jpg   \n",
       "1  2877  fb7099d23536972d11f825cd7e038c67  ../data/images/ISIC_1000001.jpg   \n",
       "2  1783  541e383dd5e78d1da34dae882cbee940  ../data/images/ISIC_1000002.jpg   \n",
       "3  2295  ff00ee82c9d240453d6f5da4522cfb6e  ../data/images/ISIC_1000003.jpg   \n",
       "4  2317  e89d64eadaf1a1af2e273c001edadda2  ../data/images/ISIC_1000004.jpg   \n",
       "\n",
       "               cell_type  cell_type_idx  train_or_val_or_test  \n",
       "0               Melanoma              0                 train  \n",
       "1     IEC/Bowens disease              3                 train  \n",
       "2                 Naevus              1                 train  \n",
       "3  Seborrhoeic keratosis              4                 train  \n",
       "4     IEC/Bowens disease              3                 train  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if a row belongs to the train or val or test set\n",
    "def get_val_rows(x):\n",
    "    # create a list of all the imageid in the val set\n",
    "    val_list = list(df_val['image'])\n",
    "    test_list = list(df_test['image'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    elif str(x) in test_list:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n",
    "    \n",
    "# identify train and val rows\n",
    "# create a new column that \n",
    "df['train_or_val_or_test'] = df['image']\n",
    "df['train_or_val_or_test'] = df['train_or_val_or_test'].apply(get_val_rows)\n",
    "# filter out train rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Naevus                    3888\n",
       "Basal Cell Carcinoma      3181\n",
       "IEC/Bowens disease        2560\n",
       "Keratosis pilaris         2079\n",
       "Seborrhoeic keratosis     1862\n",
       "Squamous cell carcinom     710\n",
       "Melanoma                   581\n",
       "dermatofibroima            219\n",
       "vascular lesions           117\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3888\n",
       "2    3181\n",
       "3    2560\n",
       "8    2079\n",
       "4    1862\n",
       "7     710\n",
       "0     581\n",
       "5     219\n",
       "6     117\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3888\n",
       "6    3861\n",
       "4    3724\n",
       "5    3723\n",
       "7    3550\n",
       "0    3486\n",
       "2    3181\n",
       "3    2560\n",
       "8    2079\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy fewer class to balance the number of 7 classes\n",
    "# we only need to augment the training set.\n",
    "import math\n",
    "def balance_frame(frame):\n",
    "    aug_rate = []\n",
    "    max_size = 0\n",
    "    for i in range(9):\n",
    "        current_size = frame['cell_type_idx'].value_counts()[i]\n",
    "        if current_size > max_size:\n",
    "            max_size = current_size\n",
    "\n",
    "    for i in range(9):\n",
    "        aug_rate.append(math.floor(max_size/frame['cell_type_idx'].value_counts()[i]))\n",
    "\n",
    "    for i in range(9):\n",
    "        if aug_rate[i]:\n",
    "            frame = frame.append([frame.loc[frame['cell_type_idx'] == i,:]]*(aug_rate[i]-1), ignore_index=True)\n",
    "    return frame\n",
    "\n",
    "df_train = balance_frame(df_train)\n",
    "df_train['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting indexes! Very important!!\n",
    "df_train = df_train.reset_index()\n",
    "df_val = df_val.reset_index()\n",
    "df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "# feature_extract is a boolean that defines if we are finetuning or feature extracting. \n",
    "# If feature_extract = False, the model is finetuned and all model parameters are updated. \n",
    "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # each of these variable is model specific\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    if model_name == 'resnet':\n",
    "        \"\"\"Resnet18, Resnet34, Resnet50, Resnet101\"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == 'vgg':\n",
    "        '''VGG11_BN'''\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[9].in_features\n",
    "        model_ft.classifier[9] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == 'densenet':\n",
    "        '''densenet121'''\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    elif model_name == 'inception':\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# resnet,vgg,densenet,inception\n",
    "model_name = 'densenet'\n",
    "num_classes = 9\n",
    "feature_extract = False\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# Define the device:\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "# Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "# norm_mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "# norm_std = (0.24703233, 0.24348505, 0.26158768)\n",
    "# define the transformation of the train images.\n",
    "print(input_size)\n",
    "train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n",
    "# define the transformation of the val images.\n",
    "val_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(), \n",
    "                                     transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pytorch dataloader for this dataset\n",
    "class skinlesionDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training set using the table train_df and using our defined transitions (train_transform)\n",
    "training_set = skinlesionDataset(df_train, transform=train_transform)\n",
    "validation_set = skinlesionDataset(df_val, transform=val_transform)\n",
    "test_set = skinlesionDataset(df_test, transform=test_transform)\n",
    "\n",
    "#loaders\n",
    "train_loader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(validation_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size= 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainiter = iter(val_loader)\n",
    "# features, labels = next(trainiter)\n",
    "# features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use Adam optimizer, use cross entropy loss as our loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used during training process, to calculation the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 940], [train loss 1.26314], [train acc 0.55906]\n",
      "[epoch 1], [iter 200 / 940], [train loss 1.24343], [train acc 0.56453]\n",
      "[epoch 1], [iter 300 / 940], [train loss 1.23041], [train acc 0.56833]\n",
      "[epoch 1], [iter 400 / 940], [train loss 1.22850], [train acc 0.57117]\n",
      "[epoch 1], [iter 500 / 940], [train loss 1.22451], [train acc 0.57125]\n",
      "[epoch 1], [iter 600 / 940], [train loss 1.21775], [train acc 0.57281]\n",
      "[epoch 1], [iter 700 / 940], [train loss 1.20554], [train acc 0.57554]\n",
      "[epoch 1], [iter 800 / 940], [train loss 1.20072], [train acc 0.57602]\n",
      "[epoch 1], [iter 900 / 940], [train loss 1.19208], [train acc 0.57861]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.65296], [val acc 0.38438]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 1], [val loss 1.65296], [val acc 0.38438]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 / 940], [train loss 1.11869], [train acc 0.60500]\n",
      "[epoch 2], [iter 200 / 940], [train loss 1.11620], [train acc 0.60359]\n",
      "[epoch 2], [iter 300 / 940], [train loss 1.11405], [train acc 0.60448]\n",
      "[epoch 2], [iter 400 / 940], [train loss 1.10230], [train acc 0.60648]\n",
      "[epoch 2], [iter 500 / 940], [train loss 1.09654], [train acc 0.60931]\n",
      "[epoch 2], [iter 600 / 940], [train loss 1.09609], [train acc 0.61000]\n",
      "[epoch 2], [iter 700 / 940], [train loss 1.09434], [train acc 0.60920]\n",
      "[epoch 2], [iter 800 / 940], [train loss 1.09872], [train acc 0.60727]\n",
      "[epoch 2], [iter 900 / 940], [train loss 1.09000], [train acc 0.61101]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.50711], [val acc 0.45729]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 2], [val loss 1.50711], [val acc 0.45729]\n",
      "*****************************************************\n",
      "[epoch 3], [iter 100 / 940], [train loss 1.05011], [train acc 0.61156]\n",
      "[epoch 3], [iter 200 / 940], [train loss 1.04083], [train acc 0.62016]\n",
      "[epoch 3], [iter 300 / 940], [train loss 1.04840], [train acc 0.61833]\n",
      "[epoch 3], [iter 400 / 940], [train loss 1.03484], [train acc 0.62406]\n",
      "[epoch 3], [iter 500 / 940], [train loss 1.02524], [train acc 0.63025]\n",
      "[epoch 3], [iter 600 / 940], [train loss 1.02770], [train acc 0.62938]\n",
      "[epoch 3], [iter 700 / 940], [train loss 1.02559], [train acc 0.63018]\n",
      "[epoch 3], [iter 800 / 940], [train loss 1.02474], [train acc 0.62938]\n",
      "[epoch 3], [iter 900 / 940], [train loss 1.02246], [train acc 0.63042]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.53759], [val acc 0.44757]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 940], [train loss 0.97113], [train acc 0.65187]\n",
      "[epoch 4], [iter 200 / 940], [train loss 0.97598], [train acc 0.64719]\n",
      "[epoch 4], [iter 300 / 940], [train loss 0.98168], [train acc 0.64854]\n",
      "[epoch 4], [iter 400 / 940], [train loss 0.97594], [train acc 0.64914]\n",
      "[epoch 4], [iter 500 / 940], [train loss 0.97301], [train acc 0.65106]\n",
      "[epoch 4], [iter 600 / 940], [train loss 0.97561], [train acc 0.64938]\n",
      "[epoch 4], [iter 700 / 940], [train loss 0.97645], [train acc 0.64924]\n",
      "[epoch 4], [iter 800 / 940], [train loss 0.97215], [train acc 0.65008]\n",
      "[epoch 4], [iter 900 / 940], [train loss 0.96972], [train acc 0.65108]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.69585], [val acc 0.40538]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 940], [train loss 1.04319], [train acc 0.63250]\n",
      "[epoch 5], [iter 200 / 940], [train loss 0.98133], [train acc 0.64922]\n",
      "[epoch 5], [iter 300 / 940], [train loss 0.96472], [train acc 0.65354]\n",
      "[epoch 5], [iter 400 / 940], [train loss 0.94823], [train acc 0.65945]\n",
      "[epoch 5], [iter 500 / 940], [train loss 0.94613], [train acc 0.65794]\n",
      "[epoch 5], [iter 600 / 940], [train loss 0.93885], [train acc 0.65917]\n",
      "[epoch 5], [iter 700 / 940], [train loss 0.93443], [train acc 0.66040]\n",
      "[epoch 5], [iter 800 / 940], [train loss 0.93139], [train acc 0.66137]\n",
      "[epoch 5], [iter 900 / 940], [train loss 0.92649], [train acc 0.66410]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.56232], [val acc 0.43281]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [iter 100 / 940], [train loss 0.88604], [train acc 0.68094]\n",
      "[epoch 6], [iter 200 / 940], [train loss 0.86799], [train acc 0.68422]\n",
      "[epoch 6], [iter 300 / 940], [train loss 0.86776], [train acc 0.68260]\n",
      "[epoch 6], [iter 400 / 940], [train loss 0.87895], [train acc 0.67922]\n",
      "[epoch 6], [iter 500 / 940], [train loss 0.87159], [train acc 0.68069]\n",
      "[epoch 6], [iter 600 / 940], [train loss 0.87315], [train acc 0.67974]\n",
      "[epoch 6], [iter 700 / 940], [train loss 0.87017], [train acc 0.68129]\n",
      "[epoch 6], [iter 800 / 940], [train loss 0.87205], [train acc 0.68145]\n",
      "[epoch 6], [iter 900 / 940], [train loss 0.87061], [train acc 0.68184]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 1.54707], [val acc 0.44774]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [iter 100 / 940], [train loss 0.93752], [train acc 0.66594]\n",
      "[epoch 7], [iter 200 / 940], [train loss 0.88133], [train acc 0.68094]\n",
      "[epoch 7], [iter 300 / 940], [train loss 0.86309], [train acc 0.68500]\n",
      "[epoch 7], [iter 400 / 940], [train loss 0.86281], [train acc 0.68453]\n",
      "[epoch 7], [iter 500 / 940], [train loss 0.85401], [train acc 0.68850]\n",
      "[epoch 7], [iter 600 / 940], [train loss 0.85289], [train acc 0.68849]\n",
      "[epoch 7], [iter 700 / 940], [train loss 0.84618], [train acc 0.69009]\n",
      "[epoch 7], [iter 800 / 940], [train loss 0.84286], [train acc 0.69141]\n",
      "[epoch 7], [iter 900 / 940], [train loss 0.83781], [train acc 0.69253]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 1.53156], [val acc 0.47153]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 7], [val loss 1.53156], [val acc 0.47153]\n",
      "*****************************************************\n",
      "[epoch 8], [iter 100 / 940], [train loss 0.79093], [train acc 0.71531]\n",
      "[epoch 8], [iter 200 / 940], [train loss 0.78649], [train acc 0.71453]\n",
      "[epoch 8], [iter 300 / 940], [train loss 0.78442], [train acc 0.71344]\n",
      "[epoch 8], [iter 400 / 940], [train loss 0.78670], [train acc 0.71328]\n",
      "[epoch 8], [iter 500 / 940], [train loss 0.78849], [train acc 0.71156]\n",
      "[epoch 8], [iter 600 / 940], [train loss 0.79033], [train acc 0.71089]\n",
      "[epoch 8], [iter 700 / 940], [train loss 0.79175], [train acc 0.71013]\n",
      "[epoch 8], [iter 800 / 940], [train loss 0.79121], [train acc 0.71105]\n",
      "[epoch 8], [iter 900 / 940], [train loss 0.79229], [train acc 0.71017]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 1.57313], [val acc 0.46997]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [iter 100 / 940], [train loss 0.75320], [train acc 0.72875]\n",
      "[epoch 9], [iter 200 / 940], [train loss 0.75473], [train acc 0.72578]\n",
      "[epoch 9], [iter 300 / 940], [train loss 0.74560], [train acc 0.72760]\n",
      "[epoch 9], [iter 400 / 940], [train loss 0.74666], [train acc 0.72594]\n",
      "[epoch 9], [iter 500 / 940], [train loss 0.74632], [train acc 0.72456]\n",
      "[epoch 9], [iter 600 / 940], [train loss 0.74752], [train acc 0.72406]\n",
      "[epoch 9], [iter 700 / 940], [train loss 0.74835], [train acc 0.72482]\n",
      "[epoch 9], [iter 800 / 940], [train loss 0.75433], [train acc 0.72305]\n",
      "[epoch 9], [iter 900 / 940], [train loss 0.76006], [train acc 0.72125]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 1.52239], [val acc 0.47205]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 9], [val loss 1.52239], [val acc 0.47205]\n",
      "*****************************************************\n",
      "[epoch 10], [iter 100 / 940], [train loss 0.77717], [train acc 0.70781]\n",
      "[epoch 10], [iter 200 / 940], [train loss 0.76815], [train acc 0.71391]\n",
      "[epoch 10], [iter 300 / 940], [train loss 0.74658], [train acc 0.72427]\n",
      "[epoch 10], [iter 400 / 940], [train loss 0.73719], [train acc 0.72852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10], [iter 500 / 940], [train loss 0.73302], [train acc 0.72950]\n",
      "[epoch 10], [iter 600 / 940], [train loss 0.73073], [train acc 0.73094]\n",
      "[epoch 10], [iter 700 / 940], [train loss 0.72649], [train acc 0.73210]\n",
      "[epoch 10], [iter 800 / 940], [train loss 0.72673], [train acc 0.73270]\n",
      "[epoch 10], [iter 900 / 940], [train loss 0.72899], [train acc 0.73233]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [val loss 1.57952], [val acc 0.46927]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    tot_labels = torch.tensor([], device='cuda:0')\n",
    "    tot_outputs= torch.tensor([], device='cuda:0')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "                \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if len(tot_labels) == 0:\n",
    "                tot_labels = labels\n",
    "                tot_outputs = predicted\n",
    "            else:\n",
    "                tot_labels = torch.cat((tot_labels, labels), 0)\n",
    "                tot_outputs = torch.cat((tot_outputs, predicted), 0)\n",
    "                \n",
    "                \n",
    "    return (correct * 100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.8421052631579"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'MEL', 1: 'NV', 2: 'BCC', 3: 'AK', 4: 'BKL', 5: 'DF', 6: 'VASC', 7: 'SCC', 8: 'UNK'}\n"
     ]
    }
   ],
   "source": [
    "img_category = {lesion_category[k]: k for k in lesion_category.keys()}\n",
    "print(img_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_by_class(model):\n",
    "    class_correct = list(0. for i in range(9))\n",
    "    class_total = list(0. for i in range(9))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            _, acc_pred = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (acc_pred == labels).sum().item()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            c = (predicted == labels)\n",
    "            datalen = len(data[0])\n",
    "            #print(datalen)\n",
    "            for i in range(datalen):\n",
    "                try:\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "                except:\n",
    "                    pass\n",
    "    print('Accuracy: ', (correct * 100 / total))\n",
    "    for i in range(9):\n",
    "        print(img_category[i], class_correct[i], '/', class_total[i])\n",
    "        print('Accuracy of %20s : %3d %%' % (img_category[i], 100 * class_correct[i]/class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  46.8421052631579\n",
      "MEL 32.0 / 72.0\n",
      "Accuracy of                  MEL :  44 %\n",
      "NV 314.0 / 486.0\n",
      "Accuracy of                   NV :  64 %\n",
      "BCC 239.0 / 398.0\n",
      "Accuracy of                  BCC :  60 %\n",
      "AK 111.0 / 320.0\n",
      "Accuracy of                   AK :  34 %\n",
      "BKL 83.0 / 233.0\n",
      "Accuracy of                  BKL :  35 %\n",
      "DF 10.0 / 27.0\n",
      "Accuracy of                   DF :  37 %\n",
      "VASC 3.0 / 15.0\n",
      "Accuracy of                 VASC :  20 %\n",
      "SCC 48.0 / 89.0\n",
      "Accuracy of                  SCC :  53 %\n",
      "UNK 50.0 / 260.0\n",
      "Accuracy of                  UNK :  19 %\n"
     ]
    }
   ],
   "source": [
    "test_by_class(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft",
   "language": "python",
   "name": "pysyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
